{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.decomposition import PCA\n",
    "from pyefd import elliptic_fourier_descriptors\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_contour_points(contour):\n",
    "    \"\"\"Normalize contour points to a fixed number for consistency.\"\"\"\n",
    "\n",
    "    N = 250 # Number of points to normalize to\n",
    "    contour_length = np.linspace(0, 1, len(contour)) # Length of the contour\n",
    "    normalized_length = np.linspace(0, 1, N) # Normalized length\n",
    "    interp_func_x = interp1d(contour_length, contour[:, 0], kind='linear') # Interpolation function for x\n",
    "    interp_func_y = interp1d(contour_length, contour[:, 1], kind='linear') # Interpolation function for y\n",
    "    normalized_contour = np.vstack((interp_func_x(normalized_length), interp_func_y(normalized_length))).T # Interpolated contour\n",
    "    return normalized_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_and_extract_contours(folder_path):\n",
    "    \"\"\"Read images from a folder and extract their largest external contour.\n",
    "\n",
    "    Returns a list of normalized contour points for each image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the images from the folder\n",
    "    images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Saving the contours of the images in the list\n",
    "    contours_list = []\n",
    "\n",
    "    for image_path in images:\n",
    "        \"\"\"\n",
    "        1. Read the image\n",
    "        2. Convert to grayscale\n",
    "        3. Threshold the image\n",
    "        4. Find the contours if any are present\n",
    "        5. Get the largest contour\n",
    "        6. Remove single dimensional entries from the contour\n",
    "        7. Normalize the contour points and append to the list\n",
    "        \"\"\"\n",
    "        image = cv2.imread(image_path) # Read the image \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert to grayscale\n",
    "        _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY) # Threshold the image\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # Find the contours\n",
    "        if contours: # If contours are found\n",
    "            contour = max(contours, key=cv2.contourArea) # Get the largest contour\n",
    "            contour = contour.squeeze() # Remove single-dimensional entries from the contour\n",
    "            contours_list.append(normalize_contour_points(contour)) # Normalize the contour points\n",
    "    return contours_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fourier_coefficients(contour, order=30):\n",
    "    \"\"\"Compute Fourier coefficients for a given contour.\"\"\"\n",
    "\n",
    "    coeffs = elliptic_fourier_descriptors(contour, order=order, normalize=True) # Compute Fourier coefficients\n",
    "    #return coeffs[1:]  # Skip the first coefficient as it's related to the image position\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_averages(fourier_descriptors, labels, n_clusters):\n",
    "    \"\"\"Compute average Fourier coefficients for each cluster.\"\"\"\n",
    "    \n",
    "    sums = [np.zeros(fourier_descriptors[0].shape) for _ in range(n_clusters)]\n",
    "    counts = [0] * n_clusters\n",
    "    for coeffs, label in zip(fourier_descriptors, labels):\n",
    "        sums[label] += coeffs\n",
    "        counts[label] += 1\n",
    "    averages = [sums[i] / counts[i] if counts[i] > 0 else None for i in range(n_clusters)]\n",
    "    return averages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potatot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
